# Restaurant Sales Analysis Using Apache Spark

This project demonstrates big data processing, analysis, and visualization using Apache Spark on the Databricks platform. By integrating and analyzing sales and menu data, I extracted actionable insights to understand customer behavior, sales trends, and product performance.

---

## Project Overview

Using Apache Spark, the project processes and analyzes two datasets:

### 1. Menu: Information about food items and their prices.
### 2. Sales: Data on customer orders, including dates, locations, and order sources.

Key insights derived from the analysis include:

Total sales by year, month, and quarter.
Top 5 ordered food items.
Frequency of customer visits to restaurants.
Sales analysis by country and order source.

## Key Functions in the Notebook

### 1. Data Loading:
Load the menu and sales datasets using predefined schemas.

### 2. Aggregations:
Calculate sales metrics by food category, customer, and order source.

### 3. Time Analysis:
Generate sales reports by year, quarter, and month.

### 4. Customer Behavior:
Track customer visits to restaurants and their spending patterns.

### 5. Visualization:
Present data insights using Spark's display feature.

## Objectives and Outcomes

The primary goal was to derive meaningful business insights to support decision-making. Below are the key questions addressed:

### 1. Customer Behavior:
What is the total spending by each customer?
How frequently do customers visit restaurants?

### 2. Sales Trends:
What are the monthly, quarterly, and yearly sales trends?
What is the sales performance across different countries?

### 3. Product Analysis:
Which food items are the most popular?
How much revenue is generated by each product?

### 4. Order Insights:
Which platforms (e.g., Swiggy, Zomato) contribute the most to sales?

## Acknowledgments
Data Source: Synthetic data representing restaurant menu and sales records.
Tools Used: Apache Spark (PySpark), Databricks.
